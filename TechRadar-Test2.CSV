name,quadrant,ring,isNew,description
Container security scanning,Techniques,Adopt,TRUE,"<p>The continued adoption of containers for deployments, especially <a href=""https://www.thoughtworks.com/radar/platforms/docker"">Docker</a>, has made <strong>container security scanning</strong> a must-have technique and we've moved this technique into Adopt to reflect that. Specifically, containers introduced a new path for security issues; it's vital that you use tools to scan and check containers during deployment. We prefer using automated scanning tools that run as part of the deployment pipeline.</p>"
Data integrity at the origin,Techniques,Adopt,TRUE,"<p>Today, many organizations' answer to unlocking data for analytical usage is to build a labyrinth of data pipelines. Pipelines retrieve data from one or multiple sources, cleanse it and then transform and move it to another location for consumption. This approach to data management often leaves the consuming pipelines with the difficult task of verifying the inbound data's integrity and building complex logic to cleanse the data to meet its required level of quality. The fundamental problem is that the source of the data has no incentive and accountability for providing quality data to its consumers. For this reason, we strongly advocate for <strong>data integrity at the origin</strong>, by which we mean, any source that provides consumable data must describe its measures of data quality explicitly and guarantee those measures. The main reason behind this is that the originating systems and teams are most intimately familiar with their data and best positioned to fix it at the source. <a href=""https://www.thoughtworks.com/radar/techniques/data-mesh"">Data mesh</a> architecture takes this one step further, comparing consumable data to a <em>product</em>, where data quality and its objectives are integral attributes of every shared data set.</p>"
Micro frontends,Techniques,Adopt,FALSE,"<p>We've seen significant benefits from introducing <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a>, which have allowed teams to scale the delivery of independently deployed and maintained services. Unfortunately, we've also seen many teams create a front-end monolith — a large, entangled browser application that sits on top of the back-end services — largely neutralizing the benefits of microservices. <strong>Micro frontends</strong> have continued to gain in popularity since they were first introduced. We've seen many teams adopt some form of this architecture as a way to manage the complexity of multiple developers and teams contributing to the same user experience. In June of this year, one of the originators of this technique published an <a href=""https://martinfowler.com/articles/micro-frontends.html"">introductory article</a> that serves as a reference for micro frontends. It shows how this style can be implemented using various web programming mechanisms and builds out an example application using <a href=""https://www.thoughtworks.com/radar/languages-and-frameworks/react-js"">React.js</a>. We're confident this style will grow in popularity as larger organizations try to decompose UI development across multiple teams.</p>"
Pipelines for infrastructure as code,Techniques,Adopt,TRUE,"<p>The use of continuous delivery pipelines to orchestrate the release process for software has become a mainstream concept. CI/CD tools can be used to test server configuration (e.g., Chef cookbooks, Puppet modules, Ansible playbooks), server image building (e.g., <a href=""https://www.thoughtworks.com/radar/tools/packer"">Packer</a>), environment provisioning (e.g., <a href=""https://www.thoughtworks.com/radar/tools/terraform"">Terraform</a>, CloudFormation) and the integration of environments. The use of <strong>pipelines for infrastructure as code</strong> lets you find errors before changes are applied to operational environments — including environments used for development and testing. They also offer a way to ensure that infrastructure tooling is run consistently, using CI/CD agents rather than individual workstations. Our teams have had good results adopting this technique on their projects.</p>"
